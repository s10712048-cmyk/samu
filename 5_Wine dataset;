import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE

# --- Manual Wine Dataset ---
wine_data = pd.DataFrame({
    'alcohol':[14.23,13.20,13.16,14.37,13.24,14.20,14.39,14.06,14.83,13.86,14.10,14.12,13.75,14.75,14.38],
    'malic_acid':[1.71,1.78,2.36,1.95,2.59,1.76,1.87,2.15,1.64,1.35,2.16,1.60,1.73,1.73,1.87],
    'ash':[2.43,2.14,2.67,2.50,2.87,2.45,2.45,2.61,2.17,2.27,2.30,2.20,2.41,2.39,2.38],
    'alcalinity_of_ash':[15.6,11.2,18.6,16.8,21.0,15.2,14.6,17.6,14.0,16.0,18.0,16.0,16.0,11.4,12.0],
    'magnesium':[127,100,101,113,118,112,96,121,97,98,105,108,109,91,102],
    'total_phenols':[2.80,2.65,2.80,3.85,2.80,3.27,2.50,2.60,2.80,2.98,2.95,3.00,2.60,3.10,2.43],
    'flavanoids':[3.06,2.76,3.24,3.49,2.69,3.39,2.52,2.51,2.98,3.15,3.32,3.45,2.76,3.69,2.87],
    'nonflavanoid_phenols':[0.28,0.26,0.30,0.24,0.39,0.34,0.30,0.31,0.29,0.22,0.22,0.20,0.29,0.43,0.26],
    'proanthocyanins':[2.29,1.28,2.81,2.18,1.82,1.97,1.98,1.25,1.98,1.85,2.38,2.50,1.81,1.68,1.93],
    'color_intensity':[5.64,4.38,5.68,7.80,4.32,6.75,5.25,5.05,5.20,7.22,5.75,5.85,5.41,5.40,5.04],
    'hue':[1.04,1.05,1.03,0.86,1.04,1.05,1.02,1.06,1.08,1.01,1.25,1.09,1.05,1.03,1.04],
    'od280/od315_of_diluted_wines':[3.92,3.40,3.17,3.45,2.93,2.85,3.58,3.58,2.85,3.55,3.17,3.32,3.26,3.47,3.74],
    'proline':[1065,1050,1185,1480,735,1450,1290,1295,1045,1045,1260,1260,1190,1080,1150],
    'target':[0,0,0,0,0,1,1,1,1,1,2,2,2,2,2]
})

# --- Features & Target ---
X = wine_data.drop("target", axis=1)
y = wine_data["target"]

# --- Train-test split ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# --- Scaling ---
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)

# --- SMOTE (fixed with k_neighbors=1) ---
smote = SMOTE(random_state=42, k_neighbors=1)
X_res, y_res = smote.fit_resample(X_train_s, y_train)

# --- Logistic Regression ---
lr = LogisticRegression(multi_class="multinomial", max_iter=1000, random_state=42)
lr.fit(X_res, y_res)
lr_pred = lr.predict(X_test_s)

print("\nLogistic Regression:")
print(confusion_matrix(y_test, lr_pred))
print(classification_report(y_test, lr_pred))
print("Accuracy:", accuracy_score(y_test, lr_pred))

# --- Random Forest ---
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_res, y_res)
rf_pred = rf.predict(X_test_s)

print("\nRandom Forest:")
print(confusion_matrix(y_test, rf_pred))
print(classification_report(y_test, rf_pred))
print("Accuracy:", accuracy_score(y_test, rf_pred))









import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

data = load_wine()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

print(df.head())
print(df['target'].value_counts())

X = df.drop('target', axis=1)
y = df['target']

smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

print(pd.Series(y_res).value_counts())

X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))

plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Greens', fmt='d')
plt.show()

sample = X_test[0].reshape(1, -1)
print(f"Prediction: {data.target_names[model.predict(sample)[0]]}")
